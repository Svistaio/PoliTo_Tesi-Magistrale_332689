
% !TEX root = ../Testa/Principale.tex
% LTeX: language=it

\chapter[Teoria cinetica dei sistemi multiagente]{\texorpdfstring
    {Teoria cinetica dei\newline sistemi multiagente}
    {Teoria cinetica dei sistemi multiagente}%
}\label{secTCSM}

    In questo capitolo è discussa la Teoria Cinetica dei Sistemi MultiAgente (\TCSMA) necessaria per ottenere i risultati nella § \ref{secSimulazioni}.
   
    S'inizia prima dando delle nozioni generali di teoria della probabilità colle quali si deriva successivamente la celeberrima equazione di Boltzmann a partire da una descrizione stocastica delle particelle di un gas; quindi si passa a generalizzare tali risultati per mediare le interazioni tramite una struttura topologica sottostante gli agenti, sia in modo esatto che approssimato; successivamente si descrivono le equazioni cinetiche nel caso corrente; infine si conclude analizzando le ipotesi semplificative che portano dalla presente teoria a quella classica di Boltzmann.

    \section{Definizioni preliminari}

        Si annoverano ora molti concetti di teoria della probabilità avvisando, però, che per molti di essi è impossibile entrare eccessivamente nei dettagli senza spiegare un intero corso; in ogni caso si rimanda a \cite{Durrett2019PTE} per gl'interessati.

        \begin{dfn}[Variabile aleatoria]
            \label{defVariabileAleatoria}
            Una variabile aleatoria (v.a.) \(X\) è una funzione misurabile \(X\colon\Omega\to\mathbb R\), il cui dominio è uno spazio astratto \(\Omega\) di eventi; quest'ultimo definisce a sua volta uno spazio di probabilità \((\Omega,\mathcal F,\mathbb P)\) composto da una \(\sigma\)-algebra \(\mathcal F\) e una misura \(\mathbb P\) di massa unitaria.
        \end{dfn}

        \begin{dfn}[Legge di X]
            \label{defLeggeScalare}
            Sia \(X\in\mathbb R\) una v.a. assolutamente continua, allora \(f\colon\mathbb R\times[0,+\infty)\to\mathbb R_+\) è detta legge per \(X\) sse
            \[
                \mathbb P(X\in A)=\int_Af_X(x,t)\de x
                \quad\forall A\subseteq\mathbb R\text{ misurabile},
            \]
            e soddisfà la condizione di normalità
            \[
                \mathbb P(X\in\mathbb R)=\int_{\mathbb R}f_X(x,t)\de x=1
                \quad\forall t\in[0,+\infty).
            \]
        \end{dfn}

        \begin{oss}
            Nella definizione precedente si assume che la v.a. \(X\) sia assolutamente continua, in tal modo \(f_X(x,t)\) è la sua derivata di Radon-Nikodym, ma la teoria sviluppata in questo paragrafo vale anche per misure piú astratte rispetto le quali \(f_X(x,t)dv\) va inteso come \(f_X(dv,t)\). Tuttavia, nel caso in cui \(f_X(x,t)\) sia non negativa e integrabile viene anche detta funzione di densità di probabilità.
        \end{oss}

        \begin{dfn}[Legge congiunta di \(\mathbf X\)]
            \label{defLeggeCongiunta}
            Siano \(n\in\mathbb N^+\) e \(\mathbf X=(X_1,X_2,\ldots,X_n)\in\mathbb R^n\) un vettore aleatorio assolutamente continuo, allora la legge congiunta di \(\mathbf X\) è una funzione \(f_Z\colon\mathbb R^n\times[0,+\infty)\to\mathbb R_+\) tale che
            \[
                \mathbb P(\mathbf X\in A)
                =\int_Af_{\mathbf X}(\mathbf x,t)\de\mathbf x
                =\int_Af_{\mathbf X}(\mathbf x,t)\de x_1\de x_2\cdots\de x_n
                \quad\forall A\subseteq\mathbb R^n\text{ misurabile},
            \]
            e soddisfà la condizione di normalità
            \[
                \int_{\mathbb R}f_{\mathbf X}(\mathbf x,t)\de\mathbf x
                =\int_{\mathbb R}f_{\mathbf X}(\mathbf x,t)\de x_1\de x_2\cdots\de x_n
                =1\quad\forall t.
            \]
        \end{dfn}

        \begin{dfn}[Legge marginale di \(\mathbf X\)]
            \label{defLeggeMarginale}
            Siano \(n\in\mathbb N^+\) e \[\mathbf X=(X_1,X_2,\ldots,X_n)\in\mathbb R^n\] un vettore aleatorio assolutamente continuo, allora la legge marginale di \(X_i\) è la funzione \(f_{X_i}\colon\mathbb R\times[0,+\infty)\to\mathbb R_+\) cosí definita
            %
            \begin{equation}
                \label{eqLeggeMarginale}
                f_{X_i}(x,t)=\int_{\mathbb R^{n-1}}
                f_{\mathbf X}(\mathbf x,t)\de x_1\de x_2\cdots\de x_{i-1}\de x_{i+1}\cdots\de x_n
                \quad\forall i\in\{1,2,\cdots,n\};
            \end{equation}
            %
            essa è a tutti gli effetti la legge della v.a. \(X_i\) secondo la \cref{defLeggeScalare}.
        \end{dfn}

        \begin{oss}
            Nelle definizioni precedenti il tempo dev'essere visto come un parametro che indicizza le varie leggi degli oggetti considerati; è presente per essere coerenti colla corrente trattazione, si in generale si può trascurare: \(f_X(x)\) e \(f_Z(x)\).
        \end{oss}

        \begin{prt}[Legge congiunta di variabili aleatorie indipendenti]
            \label{prtLeggeCongiuntaIndipendente}
            Siano \(n\in\mathbb N^+\) e \[\mathbf X=(X_1,X_2,\ldots,X_n)\in\mathbb R^n\] un vettore aleatorio assolutamente continuo, allora se tutte le variabili aleatorie che lo compongono sono tra loro indipendenti allora la legge congiunta di \(\mathbf X\) equivale alla produttoria di quelle marginali:
            \[
                X_i\independent X_j
                \ \forall i\neq j\in\{1,2,\ldots,n\}
                \ \ \implies\ \ 
                f_{\mathbf X}=\prod_{i=1}^nf_{X_i}.
            \]
        \end{prt}

        \begin{dfn}[Valore atteso]
            \label{defValoreAtteso}
            Sia \(X\in\mathbb R\) una v.a. assolutamente continua e data una funzione misurabile \(\varphi\colon\mathbb R\to\mathbb R\) arbitraria, allora il valore atteso della v.a. \(\varphi(X)\) è definito come
            \[
                \mathbb E[\varphi(X)]\equiv\int_{\mathbb R}\varphi(x)f(x,t)\de x,
            \]
            e un simile discorso vale anche per un vettore aleatorio ma con \(\varphi\colon\mathbb R^n\to\mathbb R\), preso \(n\in\mathbb N^+\):
            \[
                \mathbb E[\varphi(\mathbf X)]
                \equiv\int_{\mathbb R^n}\varphi(\mathbf x)f_{\mathbf X}(\mathbf xx,t)\de\mathbf x
                =\int_{\mathbb R^n}\varphi(\mathbf x)f_{\mathbf X}(\mathbf xx,t)\de x_1\de x_2\cdots\de x_n
            \]
        \end{dfn}

        \begin{dfn}[Valore atteso condizionato]
            Sia \(X\in\mathbb R\) una v.a. assolutamente continua a media finita \(\mathbb E[X]<\infty\) e sia \(\mathcal G\subseteq\mathcal F\) una sotto-\(\sigma\)-algebra, allora l'attesa di \(X\) condizionata a \(\mathcal G\) è una v.a. \(Y\) tale che

            \begin{enumerate}[
                label=AC\arabic*,
                topsep=0.5em,
                parsep=0em,
                itemsep=0.25em,
                leftmargin=3em,
                rightmargin=1.5em,
                % \leftmargin + \itemindent = \labelindent + \labelwidth + \labelsep
                %itemindent=!,
                %labelindent=3em,
                %labelwidth=!,
                %labelsep=!,
            ]
                \item\label{ipAttesaCondizionataGMisurabile} \(\sigma(Y)\in\mathcal G\), ossia \(Y\) è \(\mathcal G\)-misurabile e
                \item\label{ipAttesaCondizionataUgualeMisura} per ogni \(A\in\mathcal G\) la misura di \(X\) e \(Y\) tramite \(\mathbb P\) è la stessa:
                    \[
                        \mathbb P(X\in A)=\int_AX\de\mathbb P=\int_AY\de\mathbb P=\mathbb P(Y\in A)
                    \]
            \end{enumerate}

            L'insieme delle \(Y\) che soddisfanno le \ref{ipAttesaCondizionataGMisurabile} e \ref{ipAttesaCondizionataUgualeMisura} sono indicate col simbolo \(\mathbb E[X|\mathcal G]\) che ne è anche il suo rappresentante; in effetti una generica \(Y\) si può indicare anche direttamente come \(\mathbb E[X|\mathcal G]\).

            Un'analoga definizione vale anche per i vettori aleatori e per i caso misti con \(X\) scalare e \(Y\) vettoriale.
        \end{dfn}

        \begin{oss}
            Presa una v.a. \(Y\in\mathbb R\), nella precedente definizione \(\mathcal G\) può essere anche la \(\sigma\)-algebra definita da \(Y\):
            \[
                \sigma(Y)\equiv\sigma({Y^{-1}(B)\ |\ B\in\mathcal B(\mathbb R)}),
            \]
            ove \(\mathcal B(\mathbb R)\) è la \(\sigma\)-algebra di Borell relativa allo spazio dei numeri reali mentre \(\sigma(A)\) è la piú piccola \(\sigma\)-algebra che contiene \(A\subset\mathcal P(\Omega)\).

            Un simile risultato vale anche per i vettori aleatori \(\mathbf Y\in\mathbb R^n\).
        \end{oss}

        \begin{prp}
            \label{prpAttesaCondizionataInterpretazionePratica}
            Dati

            \begin{enumerate}[
                label=\arabic*.,
                topsep=0.5em,
                parsep=0em,
                itemsep=0.25em,
                leftmargin=2em,
                rightmargin=1.5em,
                % \leftmargin + \itemindent = \labelindent + \labelwidth + \labelsep
                %itemindent=!,
                %labelindent=3em,
                %labelwidth=!,
                %labelsep=!,
            ]
                \item \(n,h,k\in\mathbb N_+\) tali che \(n=h+k\);
                \item un vettore aleatorio \(\mathbf Z=(\mathbf X,\mathbf Y)\in\mathbb R^n\) assolutamente continuo costituito da \(\mathbf X\in\mathbb R^h\) e \(\mathbf Y\in\mathbb R^k\) con legge congiunta \(f_{\mathbf Z}(\mathbf x,\mathbf y)\) e marginali \(f_{\mathbf X}\) e \(f_{\mathbf Y}\);
                \item una funzione \(\varphi\colon\mathbb R^n\to\mathbb R\) misurabile e tale che \(\mathbb E[\varphi(\mathbf Z)]=\mathbb E[(\mathbf X,\mathbf Y)]<\infty\);
            \end{enumerate}

            allora si può definire \(h\colon\mathbb R^k\to\mathbb R\) tramite la seguente equazione
            %
            \begin{equation}
                \label{eqCondizionehVettoreAleatorio}
                \int_{\mathbb R^h}h(\mathbf y)f_{\mathbf Z}(\mathbf x,\mathbf y)\de\mathbf x
                =\int_{\mathbb R^h}\varphi(\mathbf x,\mathbf y)f_{\mathbf Z}(\mathbf x,\mathbf y)\de\mathbf x
                % =\mathbb E[\varphi(\mathbf X,\mathbf y)] % Non è corretto poiché la media necessita della legge delle v.a. al suo interno ma qui è presente solo quella relativa a Z
                \quad\forall\mathbf y\in\mathbb R^k,
            \end{equation}
            %
            che soddisfà \(h(\mathbf Y)\in\mathbb E[\varphi(\mathbf X,\mathbf Y)|\mathbf Y]\).
        \end{prp}
        
        \begin{proof}
            Per la \ref{ipAttesaCondizionataGMisurabile} è sufficiente esplicitare la forma di \(\sigma(h(\mathbf Y))\):
            \[
                \sigma(h(\mathbf Y))
                \equiv\sigma({\mathbf Y^{-1}(h^{-1}(B))\ |\ B\in\mathcal B(\mathbb R)})
                \subseteq\sigma({\mathbf Y^{-1}(B)\ |\ B\in\mathcal B(\mathbb R^h)}),
            \]
            a parole si considera la controimmagine tramite \(\mathbf Y\) dei borelliani filtrati da \(h\), ragion per cui la sigma algebra non potrà che essere contenuta in quella non filtrata.  
            
            Per la \ref{ipAttesaCondizionataUgualeMisura} si verifica la condizione \(\forall A\in\sigma(\mathbf Y)\) avvalendosi della caratterizzazione di \(h(\mathbf Y)\) tramite \eqref{eqCondizionehVettoreAleatorio}:
            \[
                \begin{aligned}
                    \int_Ah(\mathbf Y)\de\mathbb P
                    &=\int_Bh(\mathbf y)f_{\mathbf Y}(\mathbf y)\de\mathbf y
                    \overset{\eqref{eqLeggeMarginale}}{=}
                    \int_Bh(\mathbf y)\int_{\mathbb R^h}f_{\mathbf Z}(\mathbf x,\mathbf y)\de\mathbf x\de\mathbf y
                    \\&=\int_B\int_{\mathbb R^h}h(\mathbf y)f_{\mathbf Z}(\mathbf x,\mathbf y)\de\mathbf x\de\mathbf y
                    \overset{\eqref{eqCondizionehVettoreAleatorio}}{=}
                    \int_B\int_{\mathbb R^h}\varphi(\mathbf x,\mathbf y)f_{\mathbf Z}(\mathbf x,\mathbf y)\de\mathbf x\de\mathbf y
                    \\&=\int_{\mathbb R^n}\mathbb1_B(\mathbf y)\varphi(\mathbf x,\mathbf y)f_{\mathbf Z}(\mathbf x,\mathbf y)\de\mathbf x\de\mathbf y
                    =\int_\Omega\mathbb1_B(\mathbf Y)\varphi(\mathbf X,\mathbf Y)\de\mathbb P
                    \\&=\int_\Omega\mathbb1_C(\mathbf Z)\varphi(\mathbf X,\mathbf Y)\de\mathbb P
                    =\int_\Omega\mathbb1_A\varphi(\mathbf X,\mathbf Y)\de\mathbb P
                    =\int_A\varphi(\mathbf X,\mathbf Y)\de\mathbb P.
                \end{aligned}
            \] % P. 127 di «Probabilità II {29-09-2022}.pdf»
            ove \(B\equiv\mathbf Y(A)\subseteq\mathbb R^k\) e \(C\equiv\mathbf Z(\mathbb R^h\times A)\subseteq\mathbb R^n\) dimodoché
            \[
                A=\mathbf Y^{-1}(B)=\mathbf Z^{-1}(C).
            \]
        \end{proof}

        \begin{oss}
            \label{ossAttesaCondizionataInterpretazionePratica}
            La precedente dimostrazione svela un'interpretazione piú pratica dell'attesa condizionata rispetto alla sua definizione alquanto teorica.

            Si consideri la \eqref{eqCondizionehVettoreAleatorio}, allora \(h(y)\) si può cosí riformulare:
            %
            \begin{equation}
                \label{eqAttesaCondizionataEvento}
                h(y)
                =\int_{\mathbb R^h}\varphi(\mathbf x,\mathbf y)
                f_{\mathbf X|\mathbf Y=\mathbf y}(\mathbf x)\de\mathbf x
                =\mathbb E[\varphi(\mathbf X,\mathbf Y)|\mathbf Y=\mathbf y]
                \quad\forall\mathbf y\in\mathbb R^k,
            \end{equation}
            %
            in cui
            \[
                f_{\mathbf X|\mathbf Y=y}
                \equiv\left\{
                    \begin{aligned}
                        &f_{\mathbf Z}(\mathbf x,\mathbf y)/f_{\mathbf Y}(\mathbf y)&\text{se }f_{\mathbf Y}(y)\neq0\\
                        &0&\text{se }f_{\mathbf Y}(y)=0
                    \end{aligned}
                \right.
            \]
            è la legge di \(\mathbf X\) condizionata dall'evento \(\mathbf Y=y\).

            La \eqref{eqAttesaCondizionataEvento}, in pratica, si calcola svolgendo la media di \(\varphi(\mathbf X,\textbf Y)\) rispetto a \(\mathbf X\) dopo aver "fissato" l'evento \(\mathbf Y=\mathbf y\), vale a dire considerando la \(\mathbf Y\) come fosse un parametro uguale a \(\mathbf y\). 

            Successivamente, se s'impone \(A=\Omega\) (sempre lecito essendo \(\mathcal G\) una \(\sigma-algebera\)) allora dalla \ref{ipAttesaCondizionataUgualeMisura} vale
            %
            \begin{equation}
                \label{eqAttesaCondizionataInterpretazionePratica}
                \mathbb E[\varphi(\mathbf X,\mathbf Y)]
                =\mathbb E[\mathbb E[\varphi(\mathbf X,\mathbf Y)|\mathbf Y]],
            \end{equation}
            %
            il che significa che l'attesa di \(\varphi(\mathbf X,\mathbf Y)\) si calcola mediando rispetto a \(\mathbf Y\) la v.a. \(\mathbb E[\mathbf X|\mathbf Y]\), ricavata dalla \eqref{eqAttesaCondizionataEvento} ma considerando \(\mathbf y\) arbitrario.
        \end{oss}

    \section{Descrizione cinetica classica}

        \subsection{Equazione di Boltzmann omogenea}
            Innanzitutto è necessario caratterizzare alcune proprietà del gas da modellizzare.

            \begin{ipo}
                \label{ipGasPerfetto}
                Si consideri un gas composto da particelle che soddisfaccia le successive importanti ipotesi:

                \begin{enumerate}[
                    label=G\arabic*,
                    topsep=0.5em,
                    parsep=0em,
                    itemsep=0.25em,
                    leftmargin=2.5em,
                    rightmargin=1.5em,
                    % \leftmargin + \itemindent = \labelindent + \labelwidth + \labelsep
                    %itemindent=!,
                    %labelindent=3em,
                    %labelwidth=!,
                    %labelsep=!,
                ]
                    \item\label{ipGasOmogeneo} è uniformemente distribuito nello spazio cosicché in ogni punto la distribuzione statistica delle velocità è la stessa;
                    \item\label{ipGasRarefatto} è rarefatto, da cui segue che solo interazioni binarie possono aver luogo o, precisamente, sono piú probabili;
                    \item\label{ipGasParticelleIndistinguibili} è composto da particelle indistinguibili e aventi ugual massa;
                    \item\label{ipGasCollisioniElastiche} le collisioni sono elastiche per cui si ha conservazione dell'impulso e dell'energia esprimibile, grazie alle \ref{ipGasRarefatto} e \ref{ipGasParticelleIndistinguibili}, binariamente come
                    %
                    \begin{align}
                        \mathbf\mathbf v'+\mathbf\mathbf v_*'
                        &=\mathbf\mathbf v+\mathbf\mathbf v_*,
                        \label{eqConservazioneImpulso}\tag{CI}\\
                        \vert\mathbf\mathbf v'\vert^2+\vert \mathbf\mathbf v_*'\vert^2&=
                        \vert\mathbf\mathbf v\vert^2+\vert \mathbf\mathbf v_*\vert^2,
                        \label{eqConservazioneEnergia}\tag{CE}
                    \end{align}
                    %
                    ove \(\mathbf v',\mathbf v'_*\in\mathbb R^3\) sono le velocità poscollisionali che collidono colle velocità precollisionali \(\mathbf v,\mathbf v_*\in\mathbb R^3\), delle due particelle interagenti\footnotemark{}.
                    \footnotetext{In questo contesto non è necessario distinguere quale delle due sia quella interagente e quale quella ricevente, contrariamente a quello delle città.}
                \end{enumerate}
            \end{ipo}

            Dalla \ref{ipGasCollisioniElastiche} si possono in realtà esprimere le velocità poscollisionali a partire da quelle precollisionali, definendo quelle che sono le leggi d'interazione.

            \begin{prp}[Leggi d'interazione]\label{prpVelocitàCollisionali}
                Esistono due funzioni \(\psi,\psi_*\colon\mathbb R^3\to\mathbb R^3\) che soddisfanno \cref{eqConservazioneImpulso,eqConservazioneEnergia} e tali che
                %
                \begin{equation}
                    \label{eqLeggiInterazioneGas}
                    \begin{aligned}
                        \mathbf v'&=\psi(\mathbf v,\mathbf v_*)\equiv\mathbf v+[(\mathbf v_*-\mathbf v)\cdot n]n,\\
                        \mathbf v'_*&=\psi_*(\mathbf v,\mathbf v_*)\equiv\mathbf v_*+[(\mathbf v-\mathbf v_*)\cdot n]n,
                    \end{aligned}
                \end{equation}
                %
                ove \(n\in\mathbb S^2\) è un qualunque vettore appartenente alla sfera unitaria di \(\mathbb R^3\).
            \end{prp}
            %
            \begin{proof}
                Assumendo l'\textit{ansatz}
                %
                \begin{equation}
                    \label{eqAnsatzCollisioni}
                    \mathbf v'=\mathbf v-\gamma n\quad\text{ e }\quad\mathbf v'_*=\mathbf v_*+\gamma n,
                \end{equation}
                %
                in cui \(\gamma\in\mathbb R\) è un parametro da determinare, si può notare che la \eqref{eqConservazioneImpulso} è già verificata, mentre imponendo la \eqref{eqConservazioneEnergia} si ha
                \[
                    \begin{aligned}
                        \vert\mathbf v'\vert^2+\vert\mathbf v_*'\vert^2
                        &=\vert\mathbf v-\gamma n\vert^2+\vert\mathbf v_*+\gamma n\vert^2\\
                        &=(\mathbf v-\gamma n)\cdot(\mathbf v-\gamma n)
                        +(\mathbf v_*+\gamma n)\cdot(\mathbf v_*+\gamma n)\\
                        &=\vert\mathbf v\vert^2-2\gamma(\mathbf v\cdot n)
                        +\gamma^2+\vert\mathbf v_*\vert^2
                        +2\gamma(\mathbf v_*\cdot n)+\gamma^2\\
                        &=\vert\mathbf v\vert^2+\vert\mathbf v_*\vert^2
                        -2\gamma[(\mathbf v_*-\mathbf v)\cdot n+2\gamma]\\
                        &=\vert\mathbf v\vert^2+\vert\mathbf v_*\vert^2
                        \ \ \implies\ \ 
                        \gamma[(\mathbf v_*-\mathbf v)\cdot n+\gamma]=0,
                    \end{aligned}
                \]
                ma escludendo il caso banale di \(\gamma=0\) (nessuna interazione) si ha
                \[
                    \gamma=\Gamma(\mathbf v,\mathbf v_*)\equiv(\mathbf v-\mathbf v_*)\cdot n,
                \]
                per cui \(\gamma\) è in realtà una funzione delle velocità precollisionali; la \eqref{eqAnsatzCollisioni} diventa allora
                %
                \begin{equation}
                    \label{eqVelocitàPoscollisionali}
                    \mathbf v'=\mathbf v+[(\mathbf v_*-\mathbf v)\cdot n]n
                    \quad\text{ e }\quad\mathbf v'_*
                    =\mathbf v_*+[(\mathbf v-\mathbf v_*)\cdot n]n.
                \end{equation}
            \end{proof}
            %
            Si noti come la precedente dimostrazione lasci arbitrario \(n\in\mathbb S^2\), seppure da un punto di vista fisico sia ragionevole porlo parallelo al vettore passante per i centri delle particelle collidenti.

            Si osservi come le leggi d'interazione nella \ref{eqLeggiInterazioneGas} sono bilineari e simmetriche secondo la seguente definzione:

            \begin{dfn}[Leggi d'interazione simmetriche]
                \label{defLeggiInterazioneSimmetriche}
                Due leggi d'interazione del tipo \eqref{eqLeggiInterazioneGas} si dicono simmetriche sse
                \[
                    \begin{aligned}
                        \psi(\mathbf v,\mathbf v_*)&=\psi_*(\mathbf v_*,\mathbf v)\\
                        \psi_*(\mathbf v,\mathbf v_*)&=\psi(\mathbf v_*,\mathbf v)
                    \end{aligned}
                    \ \ \implies\ \ 
                    \begin{aligned}
                        \mathbf v'&=\psi_*(\mathbf v_*,\mathbf v)\\
                        \mathbf v'_*&=\psi(\mathbf v_*,\mathbf v)
                    \end{aligned}
                \]
            \end{dfn}

            Per proseguire è però necessaria una descrizione statistica del gas in esame: siano allora \(\mathbf V_t,\mathbf V_t^*\in\mathbb R^3\) le v.a. delle velocità precollisionali, di cui le \(\mathbf v\) e \(\mathbf v_*\) precedenti sono due realizzazioni, al tempo \(t\) e similmente per \(\mathbf V'_t,\mathbf V^{*\prime}_t\in\mathbb R^3\).

            \begin{oss}
                \label{ossLeggiIndistinguibili}
                Le v.a. \(\mathbf V_t\) e \(\mathbf V^*_t\) non sono indicizzate (per es. \(\mathbf V^i_t\)) proprio per l'indistinguibilità delle particelle assunta dalla \ref{ipGasParticelleIndistinguibili}, dalla quale si deduce anche che le leggi di \(\mathbf V_t\) e \(\mathbf V^*_t\) sono identiche:
                \[
                    f_{\mathbf V_t}(\mathbf v,t)=f_{\mathbf V^*_t}(\mathbf v,t)=f(\mathbf v,t)\quad\forall \mathbf v\in\mathbb R^3.
                \]
            \end{oss}

            Le leggi d'interazione nella \eqref{eqLeggiInterazioneGas} diventano
            %
            \begin{equation}
                \label{eqVelocitàPosCollisionaliStatistiche}
                \begin{aligned}
                    \mathbf V'&=\psi(V,\mathbf V_*)\equiv\mathbf V+[(\mathbf V_*-\mathbf V)\cdot n]n,\\
                    \mathbf V'_*&=\psi_*(\mathbf V,\mathbf V_*)\equiv \mathbf V_*+[(\mathbf V-\mathbf V_*)\cdot n]n,
                \end{aligned}
            \end{equation}
            %
            in cui anche \(n\) risulta aleatoriamente distribuito; usualmente s'ipotizza \(n\sim\mathcal U(\mathbb S^2)\), vale a dire che non vi sono direzioni preferenziali essendo queste uniformemente distribuite sulla sfera unitaria.

            Tuttavia l'interazione tra due particelle non è detto che avvenga, aspetto formulabile introducendo 
            %
            \begin{equation}
                \label{eqBernoulliInterazione}
                \Theta\sim\DstrBernoulli(B((\mathbf V^*_t-\mathbf V_t)\cdot n)\Delta t)
            \end{equation}
            %
            che è una v.a. di Bernoulli, indipendente da \(\mathbf V_t\) e \(\mathbf V^*_t\), la cui probabilità è descritta da due termini:
            
            \begin{enumerate}[
                label=\arabic*.,
                topsep=0.5em,
                parsep=0em,
                itemsep=0.25em,
                leftmargin=2em,
                rightmargin=1.5em,
                % \leftmargin + \itemindent = \labelindent + \labelwidth + \labelsep
                %itemindent=!,
                %labelindent=3em,
                %labelwidth=!,
                %labelsep=!,
            ]
                \item la funzione \(B\colon\mathbb R\to\mathbb R_+\), detta nucleo di collisione, che permette d'avere una maggiore espressività sulle collisioni molecolari le quali possono influenzare il tasso d'interazione tra le molecole\footnotemark{};
                \footnotetext{Si noti come \(B\) dipenda da \((\mathbf V_*-\mathbf V)\cdot n\), termine ripreso dalla \cref{prpVelocitàCollisionali}, cosa che permette d'interpretare \(n\) come la direzione lungo la quale le interazioni sono piú frequenti.}
                \item un passo temporale \(\Delta t>0\) per discretizzare il tempo.
            \end{enumerate}
            
            \begin{oss}
                \label{ossCondizioneTetaGas}
                Per definizione di \(\Theta\), deve valere \(B((\mathbf V^*_t-\mathbf V_t)\cdot n)\Delta t\le1\) condizione soddisfacibile anche prendendo un passo temporale \(\Delta t\) adattivo; si vedrà tra poco, però, che, per quanto concerne il modello analitico, tale condizione sarà sempre verificata.
            \end{oss}

            Colle \cref{eqVelocitàPosCollisionaliStatistiche,eqBernoulliInterazione}, lo stato dei due agenti al tempo \(t+\Delta t\) successivo è dunque dato dal seguente algoritmo d'interazione:
            %
            \begin{equation*}
                \def\theequation{[AR]}
                \refstepcounter{equation}
                \label{eqAlgoritmoInterazioniAzioneReazione}
                [AR]\left\{
                \begin{aligned}
                    \mathbf V_{t+\Delta t}   & =(1-\Theta)\mathbf V_t+\Theta\mathbf V'_t,            \\
                    \mathbf V^*_{t+\Delta t} & =(1-\Theta)\mathbf V^*_t+\Theta\mathbf V^{*\prime}_t,
                \end{aligned}
                \right.
                \notag
            \end{equation*}
            %
            dove l'acronimo \ref{eqAlgoritmoInterazioniAzioneReazione} sta per «Azione-Reazione» e descrive il fatto che ogni interazione (azione) necessariamente modifica entrambi gli stati degli agenti coinvolti (reazione); in alcuni contesti \cite{Nurisso2024} questa regola può essere alterata dimodoché solo il nodo interagente sia modificato portando alle interazioni «Azione-Azione».

            L'idea successiva, al fine di ricavare un modello dell'evoluzione di \(f\), è di mediare le \ref{eqAlgoritmoInterazioniAzioneReazione} attraverso una funzione arbitraria \(\varphi\colon\mathbb R^3\to\mathbb R\), detta quantità osservabile, computabile dalle realizzazioni o di \(\mathbf V_{t+\Delta t}\) o di \(\mathbf V_{t+\Delta t}\); pertanto una volta applicato \(\varphi(\cdot)\) alle \ref{eqAlgoritmoInterazioniAzioneReazione},
            %
            \begin{equation*}
                \begin{aligned}
                    \varphi(\mathbf V_{t+\Delta t})&=\varphi((1-\Theta)\mathbf V_t+\Theta\mathbf V'_t),\\
                    \varphi(\mathbf V^*_{t+\Delta t})&=\varphi((1-\Theta)\mathbf V^*_t+\Theta\mathbf V^{*\prime}_t),
                \end{aligned}
            \end{equation*}
            %
            e mediando \(\mathbb E[\cdot]\) si arriva a
            %
            \begin{equation*}
                \begin{aligned}
                    \mathbb E[\varphi(\mathbf V_{t+\Delta t})]&=\mathbb E[\varphi((1-\Theta)\mathbf V_t+\Theta\mathbf V'_t)],\\
                    \mathbb E[\varphi(\mathbf V^*_{t+\Delta t})]&=\mathbb E[\varphi((1-\Theta)\mathbf V^*_t+\Theta\mathbf V^{*\prime}_t)];
                \end{aligned}
            \end{equation*}
            %
            per espandere la media, siccome \(\Theta\) dipende da \((\mathbf V_t,\mathbf V^*_t,n)\), bisogna avvalersi dell'attesa condizionata, e in particolare della \cref{ossAttesaCondizionataInterpretazionePratica}, che porta a
            %
            \begin{equation*}
                \begin{aligned}
                    \mathbb E[\varphi(\mathbf V_{t+\Delta t})]
                    =&\mathbb E[\varphi((1-\Theta)\mathbf V_t+\Theta\mathbf V'_t)],
                    \\=&\mathbb E[\mathbb E[\varphi((1-\Theta)\mathbf V_t+\Theta\mathbf V'_t)\ |\ \mathbf V_t,\mathbf V_t^*,n]],
                    \\=&\mathbb E[\varphi(\mathbf V_t)(1-B((\mathbf V^*_t-\mathbf V_t)\cdot n)\Delta t)]
                    \\&+\mathbb E[\varphi(\mathbf V'_t)B((\mathbf V^*_t-\mathbf V_t)\cdot n)]\Delta t,
                \end{aligned}
            \end{equation*}
            %
            e similmente per \(\mathbb E[\varphi(\mathbf V^*_{t+\Delta t})]\); riordinando i termini si ricava
            %
            \begin{equation*}
                \begin{aligned}
                    \frac{\mathbb E[\varphi(\mathbf V_{t+\Delta t})]-\mathbb E[\varphi(\mathbf V_t)]}{\Delta t}
                    &=\mathbb E[B((\mathbf V^*_t-\mathbf V_t)\cdot n)(\varphi(\mathbf V'_t)-\varphi(\mathbf V_t))],\\
                    \frac{\mathbb E[\varphi(\mathbf V^*_{t+\Delta t})]-\mathbb E[\varphi(\mathbf V^*_t)]}{\Delta t}
                    &=\mathbb E[B((\mathbf V^*_t-\mathbf V_t)\cdot n)(\varphi(\mathbf V^{*\prime}_t)-\varphi(\mathbf V^*_t))],
                \end{aligned}
            \end{equation*}
            %
            e passando formalmente al tempo continuo col limite \(\Delta t\to0^+\)\footnotemark{} si ha
            \footnotetext{Ciò permette di soddisfare la condizione descritta nel'\ref{ossCondizioneTetaGas} per qualunque valore di \(B((\mathbf V^*_t-\mathbf V_t)\cdot n)\).}
            %
            \begin{equation*}
                \begin{aligned}
                    \derS{\mathbb E[\varphi(\mathbf V_t)]}t
                    &=\mathbb E[B((\mathbf V^*_t-\mathbf V_t)\cdot n)(\varphi(\mathbf V'_t)-\varphi(\mathbf V_t))],\\
                    \derS{\mathbb E[\varphi(\mathbf V^*_t)]}t
                    &=\mathbb E[B((\mathbf V^*_t-\mathbf V_t)\cdot n)(\varphi(\mathbf V^{*\prime}_t)-\varphi(\mathbf V^*_t))],
                \end{aligned}
            \end{equation*}
            %
            che, dopo aver espanso i valori attesi secondo le loro definizioni, diventano
            %
            \begin{equation}
                \label{eqInterazioniOsservabiliContinue}
                \newcommand\hsep{\hspace{-.4em}}
                \begin{aligned}
                    \derS{}t\int_{\mathbb R^3}\hsep
                    \varphi(\mathbf v)f(\mathbf v,t)\de\mathbf v
                    &=\int_{\mathbb R^6}\hsep\langle
                        B(\mathbf v,\mathbf v_*,n)
                        (\varphi(\mathbf v')-\varphi(\mathbf v))
                    \rangle f_{\mathbf V}(\mathbf v,\mathbf v_*,t)
                    \de\mathbf v\de\mathbf v_*,\\
                    \derS{}t\int_{\mathbb R^3}\hsep
                    \varphi(\mathbf v^*)f(\mathbf v_*,t)\de\mathbf v_*
                    &=\int_{\mathbb R^6}\hsep\langle
                        B(\mathbf v,\mathbf v_*,n)
                        (\varphi(\mathbf v_*')-\varphi(\mathbf v_*))
                    \rangle f_{\mathbf V}(\mathbf v,\mathbf v_*,t)
                    \de\mathbf v\de\mathbf v_*,
                \end{aligned}
            \end{equation}
            %
            in cui
            \[
                \langle\cdot\rangle\equiv\frac1{4\pi}\int_{\mathbb S^2}\cdot\de n
            \]
            indica la media rispetto a \(n\), \(B(\mathbf v,\mathbf v_*,n)\) è una forma breve per \(B((\mathbf v-\mathbf v_*)\cdot n)\) e si è posto \(\mathbf V\equiv(\mathbf V_t,\mathbf V^*_t)\) la cui legge congiunta è \(f_{\mathbf V}(\mathbf v,\mathbf v_*,t)\). È infine necessario sommare le due equazioni in \eqref{eqInterazioniOsservabiliContinue}. S'inizi dal primo membro:
            %
            \begin{equation}
                \label{eqSommaPrimoMembroIOC}
                \derS{}t\int_{\mathbb R^3}\varphi(\mathbf v)f(\mathbf v,t)\de\mathbf v+
                \derS{}t\int_{\mathbb R^3}\varphi(\mathbf v^*)f(\mathbf v_*,t)\de\mathbf v_*
                =2\derS{}t\int_{\mathbb R^3}\varphi(\mathbf v)f(\mathbf v,t)\de\mathbf v,
            \end{equation}
            %
            infatti dal'\cref{ossLeggiIndistinguibili} le due leggi sono di fatto identiche come lo è il dominio d'integrazione, quindi basta il cambio di variabile \(\mathbf v_*=\mathbf v\) nel secondo integrale per rendersi conto dell'equivalenza. Per il secondo membro sono necessarie due ulteriori fondamentali ipotesi:

            \begin{ipo}
                Si assume che il nucleo di collisione sia una funzione pari:
                %
                \begin{equation}
                    \label{eqParitàNucleoCollisioneGas}
                    B((\mathbf v-\mathbf v_*)\cdot n)=B((\mathbf v_*-\mathbf v)\cdot n)
                    \quad\forall\mathbf v,\mathbf v_*\in\mathbb R^3;
                \end{equation}
                %
                una scelta tipica è il valore assoluto \(\vert\cdot\vert\): \(B((\mathbf v-\mathbf v_*)\cdot n)\equiv\vert(\mathbf v-\mathbf v_*)\cdot n\vert\).
            \end{ipo}

            \begin{ipo}[\textit{Caos} molecolare]
                \label{ipCaosMolecolare}
                Le particelle interagenti secondo le \ref{eqAlgoritmoInterazioniAzioneReazione} sono campionante indipendentemente. Tal'ipotesi è piú facile da giustificare matematicamente che fisicamente perché semplifica di molto conti; in ogni caso, la \ref{ipGasRarefatto} la corrobora poiché in un gas rarefatto è naturale che se due particelle interagiscono, prima che ricollidano, avranno perso ogni vicendevole dipendenza a causa delle innumerevoli altre interazioni colle altre particelle.
            \end{ipo}

            \begin{oss}
                Dal'\cref{ipCaosMolecolare}, unitamente alla \cref{prtLeggeCongiuntaIndipendente}, si deduce che la legge congiunta del vettore aleatorio \(\mathbf V\equiv(\mathbf V_t,\mathbf V^*_t)\) è data dal prodotto
                \[
                    f_{\mathbf V}(\mathbf v,\mathbf v_*,t)
                    =f_{\mathbf V_t}(\mathbf v,t)f_{\mathbf V^*_t}(\mathbf v_*,t)
                    =f(\mathbf v,t)f(\mathbf v_*,t)
                    \quad\forall \mathbf v,\mathbf v_*\in\mathbb R^3.
                \]
            \end{oss}

            In tal modo il termine moltiplicato a \(\varphi(v_*)\) nel secondo membro della seconda equazione della \eqref{eqInterazioniOsservabiliContinue} può essere cosí riformulato:
            %
            \begin{equation}
                \label{eqSommaSecondoMembroIOC}
                \int_{\mathbb R^6}\langle(\varphi(\mathbf v))
                B((\mathbf v-\mathbf v_*)\cdot n)\rangle
                f(\mathbf v,t)f(\mathbf v_*,t)\de\mathbf v\de\mathbf v_*,
            \end{equation}
            %
            seguendo la medesima logica della \eqref{eqSommaPrimoMembroIOC}. Applicando i due risultati illustrati nelle \cref{eqSommaPrimoMembroIOC,eqSommaSecondoMembroIOC} si perviene finalmente alla forma debole dell'equazione di Bolztmann omogenea assimmetrica:
            %
            \begin{equation}
                \label{eqFormaDeboleBoltzmannOmogeneoAssimmetrico}
                \derS{}t\int_{\mathbb R^3}\varphi f\de\mathbf v=
                \frac1{4\pi}\int_{\mathbb R^6}\int_{\mathbb S^2}
                    B(\mathbf v,\mathbf v_*,n)
                    \left(\frac{\varphi'-\varphi'_*}2-\varphi\right)
                ff_*\de n\de\mathbf v_*\de\mathbf v,
            \end{equation}
            %
            ove, per brevità di notazione, si sono sottintese le dipendenze per tutte le funzioni, espresse, salvo per il nucleo di collisione, da apici \(\prime\) e asterischi \(*\). Tuttavia, qualora le leggi d'interazioni siano simmetriche secondo la \cref{defLeggiInterazioneSimmetriche}, come in questo caso data la \cref{prpVelocitàCollisionali}, sempre con un cambio di variabili e sfruttrando la parità del nucleo di collisione vale
            %
            \begin{equation*}
                \int_{\mathbb R^6}\left(\left\langle
                    B(\mathbf v,\mathbf v_*,n)\varphi'
                \right\rangle\right) ff_*\de\mathbf v_*\de\mathbf v,
                =\int_{\mathbb R^6}\left(\left\langle
                    B(\mathbf v,\mathbf v_*,n)\varphi'_*
                \right\rangle\right) ff_*\de\mathbf v_*\de\mathbf v,
            \end{equation*}
            %
            da cui segue la forma debole dell'equazione di Bolztmann omogenea simmetrica:
            %
            \begin{equation}
                \label{eqFormaDeboleBoltzmannOmogeneoSimmetrico}
                \derS{}t\int_{\mathbb R^3}\varphi f\de\mathbf v=
                \frac1{4\pi}\int_{\mathbb R^6}\int_{\mathbb S^2}
                    B(\mathbf v,\mathbf v_*,n)
                    \left(\varphi'-\varphi\right)
                ff_*\de n\de\mathbf v_*\de\mathbf v.
            \end{equation}
            %
            Si può anche ricavare la forma forte considerando la funzione invertendo le leggi d'interazione \eqref{eqLeggiInterazioneGas} \cite[§ 2.5, p. 15]{Loy2025EKTMAS}, ma il conto esula dagli scopi di questo elaborato; cionnonostante si riporta come riferimento la forma forte dell'equazione di Boltzmann omogenea simmetrica:
            %
            \begin{equation}
                \label{eqFormaForteBoltzmannOmogeneoSimmetrico}
                \derP ft=\frac1{4\pi}\int_{\mathbb R^3}\int_{\mathbb S^2}
                B(\mathbf v,\mathbf v_*,n)\left(f'f'_*-ff_*\right)\de n\de\mathbf v_*.
            \end{equation}

        \subsection{Equazione di Boltzmann disomogenea}

        \subsection{Equazione di tipo Boltzmann omogenea}

    \section{Descrizione cinetica retale}\label{secDescrizioneCinetica} %  d'interazioni mediante da un grafo
        
        \subsection{Impostazione}

            La popolazione degli agenti evolve a causa delle interazioni con altri agenti connessi. Seguendo la teoria cinetica collisionale, l'ipotesi fondamentale ipotizzata è che solo le interazioni binarie siano rilevanti: le interazioni fra tre o piú agenti possono essere trascurate.

            Dopodiché, sia \(X\in\mathcal I\) la posizione di un agente sul grafo \(\mathcal G=(\mathcal I,\mathcal E)\), ove \(\mathcal I\) è l'insieme dei vertici mentre \(\mathcal E\) dei lati di \(\mathcal G\). Si assume che il grafico sia statico, ovvero che le connessioni tra agenti non varia nel tempo.

            Si consideri, allora, un generico agente rappresentativo, il cui stato microscopico è descritto dal processo stocastico \((X,S_t)_{t\geq0}\); la funzione \(S_t:\Omega\to\mathcal P\) è una v.a. da uno spazio astratto \(\Omega\) allo spazio delle popolazioni \(\mathcal P\) e indica la popolazione dell'agente al tempo \(t\geq0\). Tale v.a. evolve nel tempo per le interazioni binarie con altri agenti mediate dalle connessioni descritte da \(\mathcal E\), definendo cosí un processo stocastico \(\{S_t,t\in[0,+\infty)\}\).

            Nel complesso di descrive statisticamente lo stato microscopico \(X,S_t\) dell'agente mediante una probabilità di misura \(f=f(x,s,t)\), discreta in \(x\in\mathcal I\) e continua in \(s\in\mathcal P\). Pertanto si può dare alla \(f\) la seguente forma
            %
            \begin{equation}
                \label{eqDistribuzioneTotale}
                f(x,s,t)=\frac1N\sum_{i\in\mathcal I}f_i(s,t)\otimes\delta(x-i),
            \end{equation}
            %
            ove \(N\equiv\vert\mathcal I\vert\) è il numero totale d'agenti/vertici del grafo mentre \(\delta(\cdot)\) denota la delta di Dirac centrata all'origine; d'altra parte \[f_i=f_i(s,t):\mathcal P\times[0,+\infty)\rightarrow\mathbb R_+\] è la densità di probabilità della taglia \(S_t\) dell'agente \(X=i\).
            
            Logicamente si richiede
            \begin{equation*}
                %
                % \label{eqUnitaryIntegrationfi}
                \int_{\mathcal P}f_i(s,t)\de s=1,
                \qquad\forall t\geq0,\;\forall i\in\mathcal I,
            \end{equation*}
            %
            che implica coerentemente
            %
            \begin{equation*}
                % \label{eqUnitaryIntegrationf}
                \int_{\mathcal I}\int_{\mathcal P}
                f(x,s,t)\de s\de x=1
                \qquad\forall t\geq0
            \end{equation*}

        \subsection{Algoritmi d'interazione}

            Un algoritmo d'interazione è una regola che descrive come gli agenti interagiscono a coppie e modificano di conseguenza il loro stato nel tempo; nel dettaglio, in un dato passo temporale \(\Delta t>0\) si assume che un agente \((X,S_t)\in\mathcal I\times\mathcal P\) cambi la sua popolazione a \(S_{t+\Delta t}\in\mathcal P\) a seguito di un interazione con un altro agente \((X^*,S^*_t)\in\mathcal I\times\mathcal P\) secondo il successivo schema
            %
            \begin{equation}
                \label{eqSchemaInterazioneAgenteInteragente}
                S_{t+\Delta t}=(1-\Theta)S_t+\Theta S'_t,
            \end{equation}
            %
            ove \(\Theta\in{0,1}\) è una v.a. che tiene in considerazione qualora l'interazione tra i due agenti effettivamente si manifesti \((\Theta=1)\) o no \((\Theta=0)\); d'altro canto \(S'_t\in\mathcal P\) è la nuova popolazione ottenuta dall'agente \((X,V_t)\) in seguito a un'interazione avvenuta.

            Con maggiore dettaglio si pone
            %
            \begin{equation}
                \label{eqVariabileAleatoriaInterazione}
                \Theta\sim\DstrBernoulli(A(X,X^*),\Delta t),
            \end{equation}
            %
            il che significa che la probabilità che un'interazione avvenga è proporzionale al passo temporale d'interazione \(\Delta t\) mediante un nucleo d'interazione \(A(X,X^*)=1\), che contiene le informazioni sui lati del grafo, e quindi alle connessioni tra gli agenti, ponendo
            %
            \begin{equation*}
                %\label{}
                A(X,X^*)=
                \left\{\begin{aligned}
                    1&\quad\text{se }(X,X^*)\in\mathcal E,\\
                    0&\quad\text{se }(X,X^*)\notin\mathcal E,
                \end{aligned}\right.
            \end{equation*}
            %
            dove la coppia ordinata \((X,X^*)\) denota il lato dal vertice \(X\) al vertice \(X^*\); per coerenza è necessario imporre \(\Delta t\leq1\) che impone un limite superiore al massimo passo temporale ammissibile, seppure tale condizione sia molto facile da verificare nella pratica.

            La popolazione postinterazione è una v.a. \(S'_t:\Omega\to\mathcal P\) dipendente in generale dagli stati preinterazione \(V_t\), \(V^*_t\) degli agenti integranti:
            %
            \begin{equation}
                \label{eqPopolazionePostInterazione}
                V'_t(\omega)=\Psi(S_t(\omega),S^*_t(\omega),\omega),
                \quad\omega\in\Omega,
            \end{equation}
            %
            in cui \(\Psi:\mathcal P^2\times\Omega\to\mathcal P\) è funzione nota potenzialmente stocastica. 
            
        \subsection{Interazioni azione-reazione}
            
            Nel contesto delle città è chiaro che qualora una città-nodo interagisca con un'altra entrambe debbano variare il loro stato.
            
            Sia \(S\)
            la città interagente e \(S^*\) quella subente, allora in un grafo diretto si può distinguere il senso d'interazione: quella \textit{in avanti} avviene sse \((S,S^*)\in\mathcal E\) mentre quella in indietro sse \((S^*,S)\in\mathcal E\); tuttavia questa distinzione è inutile in questo caso di grafo diretto con matrice d'adiacenza simmetrica.  Pertanto l'agente \((X^*,S^*_t)\) aggiorna la sua popolazione attraverso una regola analoga a quella dell'agente \((X,S_t)\):
            %
            \begin{equation}
                \label{eqSchemaInterazioneAgenteSubente}
                S^*_{t+\Delta t}=(1-\Theta)S^*_t+\Theta S^{*\prime}_t,
            \end{equation}
            %
            ove si osserva che la \(\Theta\) è la stessa della \eqref{eqSchemaInterazioneAgenteInteragente} la cui legge dipende da \(A(X,X^*)\) ma non da \(A(X^*,X)\); tale dettaglio è da tenere in considerazione nel caso in cui la matrice di adiacenza non sia simmetrica, ma in questo caso di simmetria non è rilevante. L'opinione postinterazione
            %
            \begin{equation*}
                %\label{}
                S'_t(\omega)=\Psi_*(S^*_t(\omega),S_t(\omega),\omega),
                \quad\omega\in\Omega,
            \end{equation*}
            %
            è definita mediante una funzione \(\Psi_*:\mathcal P^2\times\Omega\to\mathcal P\) potenzialmente diversa da \(\Psi\). Questo tipo d'interazione, prendendo come riferimento \cite[§ 2.2.1]{Nurisso2024} sarà identificato come azione-reazione, e riassunto dall'algoritmo
            %
            \begin{equation*}
                % \label{eqAlgoritmoInterazioniAzioneReazione}
                % \refstepcounter{equation}
                [AR]\left\{
                \begin{aligned}
                    S_{t+\Delta t}&=(1-\Theta)S_t+\Theta S'_t,\\
                    S^*_{t+\Delta t}&=(1-\Theta)S^*_t+\Theta S^{*\prime}_t.
                \end{aligned}
                \right.
                \notag
            \end{equation*}
            %
            Si conclude questa sezione osservando che gli agenti \((X,S_t)\), \((X^*,S^*_t)\) sono campionati casualmente e uniformemente a ogni passo temporale.

    \section{Derivazione dell'equazioni cinetiche}

        \subsection{Derivazione esatta}

            Una descrizione cinetica dell'algoritmo \refAlgIntAR{} coincide con dell'equazioni d'evoluzione per le distribuzioni di probabiltà \(f_i\) delle opinioni degli agenti; per derivarle si procede mediante un metodo classico nella teoria dei sistemi multiagente \cite{Nurisso2024,IMS2013}.

            Sia \(\Phi\equiv\Phi(x,s):\mathcal I\times\mathcal P\to\mathbb R\) un osservabile arbitrario (funzione \textit{test}), cioè una quantità che si può calcolare sapendo lo stato microscopico di un generico agente rappresentativo del sistema. Allora dalla prima equazione in \refAlgIntAR{}, valutando il valore atteso dell'osservabile postinterazione rispetto agl'indici e alla popolazione a tempo fissato, si ha \daRivedere
            %
            \begin{equation*}
                %\label{}
                \begin{aligned}
                    \mathbb E[\Phi(X,S_{t+\Delta t})]=
                    \mathbb E\left[\mathbb E\right.[
                        &\Phi\left(X,(1-\Theta)S_t
                        +\Theta\Psi(S_t,S_t^*,\omega)
                        A(X,X_*)\Delta t\right)|X,X_*
                    ]\left.\vphantom{\mathbb E}\right]\\
                    =\mathbb E\left[
                        \mathbb E\right.[
                        &\Phi(X,S_t)(1-A(X,X_*)\Delta t)
                        \\&+\Phi\left(
                            X,\Psi(S_t,S_t^*,\omega)
                        \right)A(X,X_*)\Delta t
                    ]\left.\vphantom{\mathbb E}\right],
                \end{aligned}
            \end{equation*}
            %
            da cui, riordinando i termini e dividendo ambo i membri per \(\Delta t\), si deduce
            %
            \begin{equation*}
                %\label{}
                \frac{
                    \mathbb E[\Phi(X,S_{t+\Delta t})
                    -\mathbb E[\Phi(X,S_t)]]
                }{\Delta t}=
                \mathbb E\left[
                    A(X,X_*)\left(
                        \Phi(X,\Psi(S_t,S_t^*,\omega))-\Phi(X,S_t)
                    \right)
                \right],
            \end{equation*}
            %
            laddove, prendendo il limite \(\Delta t\to0^+\), si ricava formalmente
            %
            \begin{equation}
                \label{eqDinamicaValoreAtteso1}
                \derS{\mathbb E[\Phi(X,S_t)]}t=
                \mathbb E\left[
                    A(X,X^*)\left(
                        \Phi(X,\Psi(S_t,S_t^*,\omega))-\Phi(X,S_t)
                    \right)
                \right].
            \end{equation}
            %
            Si può ricavare una simile equazione ripetendo i precedenti passaggi ma colla seconda equazione di \refAlgIntAR{}, da cui
            %
            \begin{equation}
                \label{eqDinamicaValoreAtteso2}
                \derS{\mathbb E[\Phi(X^*,S^*_t)]}t=
                \mathbb E\left[
                    A(X,X^*)\left(
                        \Phi(X^*,\Psi_*(S^*_t,S_t,\omega))-\Phi(X^*,S^*_t)
                    \right)
                \right].
            \end{equation}
            %
            Osservando che le coppie \((X,S_t)\) e \((X^*,S_t^*)\) fanno riferimento a un agente rappresentativo generico del sistema, vale \[\mathbb E[\Phi(X,S_t)]=\mathbb E[\Phi(X^*,S^*_t)]\] cosicché, sommando \cref{eqDinamicaValoreAtteso1,eqDinamicaValoreAtteso2}, si ha
            %
            \begin{equation*}
                %\label{}
                \begin{aligned}
                    \derS{\mathbb E[\Phi(X,S_t)]}t=
                    \frac12\mathbb E\bigl[
                        A(X,X^*)\bigl(
                            &\Phi(X,\Psi(S_t,S^*_t,\omega))
                            +\Phi(X^*,\Psi_*(S^*_t,S_t,\omega))
                            \\&
                            -\Phi(X,S_t)-\Phi(X^*,S^*_t)
                        \bigr)
                    \bigr],
                \end{aligned}
            \end{equation*}
            %
            ed espandendo la definizione della media si arriva a
            %
            \begin{equation}
                \label{eqDinamicaValoreAttesoEspanso}
                % \derS{}t\int_{\mathcal I}\int_{\mathcal O}
                % \Phi(x,s)f(x,s,t)\de v \de x=
                % \int_{\mathcal I^2}\int_{\mathcal O^2}A(x,x_*)
                % \frac{\langle \Phi(x,s')+\Phi(x_*,s'_*)
                % -\Phi(x,s)-\Phi(x_*,s_*)\rangle}2
                % f(x,s,t)f(x_*,s_*,t)\de s\de s_*\de x\de x_*
                \derS{}t\int_{\mathcal I}\int_{\mathcal P}
                \Phi f\de v \de x=
                \int_{\mathcal I^2}\int_{\mathcal P^2}A(x,x_*)
                \frac{\langle \Phi'+\Phi_*'-\Phi-\Phi_*\rangle}2
                ff_*\de s\de s_*\de x\de x_*,
            \end{equation}
            %
            ove [per brevità] si sono omessi gli argomenti dell'osservabile e della distribuzione \eqref{eqDistribuzioneTotale}:
            %
            \begin{equation*}
                %\label{}
                \newcommand\spazOr{\;\;\;}
                f\equiv f(x,s,t),
                \spazOr\Phi\equiv\Phi(x,s),
                \spazOr\Phi_*\equiv\Phi(x_*,s_*)
                \spazOr\Phi'\equiv\Phi(x,s')
                \spazOr\text{e}\spazOr
                \Phi_*'\equiv\Phi(x_*,s_*'),
            \end{equation*}
            %
            si è inoltre imposto
            %
            \begin{equation}
                \label{eqStatiPostInterazioni}
                s'=\Psi(s,s_*,\omega)\quad s'_*=\Psi_*(s_*,s,\omega),
            \end{equation}
            %
            mentre \(\langle\cdot\rangle\) indica il valore atteso rispetto alla potenziale stocasticità delle funzioni \(\Psi\) e \(\Psi_*\).

            Si noti che la \eqref{eqDinamicaValoreAttesoEspanso} è valida per ogni funzione \textit{test} \(\Phi\) per cui è un'equazione debole per la distribuzione \(f\). (commento su Fokker-Planck \daRivedere)

            Si osservi anche che la \eqref{eqDinamicaValoreAttesoEspanso} è scritta sotto l'ipotesi della propagazione del caos: ogni due potenziali agenti interagenti sono tra di loro campionati indipendentemente. Questa assunzione è classicamente usata, per es. nella teorica cinetica di Boltzmann, per ottenere un'equazione chiusa per la distribuzione \(f\) di una particella, siccome permette di fattorizzare la distribuzione di probabilità congiunta \(g(x,x_*,s,s_*,t)\) degli agenti interagenti nel prodotto \(f(x,s,t)f(x_*,s_*,t)\).

            Dalla \eqref{eqDinamicaValoreAttesoEspanso} con una scelta adeguata della funzione \textit{test} \(\Psi\), è possibile recuperare un sistema di equazioni debole per le \(f_i\). Sia \(\Psi(x,s)=\phi_i(x)\varphi(s)\), dove \(\phi_i:\mathcal I\to\mathbb R\) è tale che \(\phi_i(i)=1\) mentre \(\phi_i(x)=0\) per ogni \(x\in\mathcal I\setminus\{i\}\) e \(\varphi:\mathcal O\to\mathbb R\) è arbitrario. Allora usando la \eqref{eqDistribuzioneTotale} dentro la \eqref{eqDinamicaValoreAttesoEspanso} si ricava
            %
            \begin{equation}
                \label{eqBoltzmannConGrafo}
                \begin{aligned}
                    \derS{}t\int_{\mathcal P}\varphi f_i\de s=&
                    \frac1{2N}\sum_{j\in\mathcal I}A(i,j)
                    \int_{\mathcal P^2}%\int_{\mathcal P}
                    \langle\varphi'-\varphi\rangle
                    f_if^*_j\de s\de s_*\\&
                    +\frac1{2N}\sum_{j\in\mathcal I}A(j,i)
                    \int_{\mathcal P^2}%\int_{\mathcal P}
                    \langle\varphi'_*-\varphi_*\rangle
                    f_jf^*_i\de s\de s_*,%\\&
                    \quad\forall i\in\mathcal I,
                \end{aligned}
            \end{equation}
            %
            ove gli argomenti di tutte le funzioni sono stati sottintesi, vale a dire
            \[
                \newcommand\spazOr{\;\;\;}
                f_i\equiv f_i(s,t)\spazOr\forall i\in\mathcal I,
                \spazOr\varphi\equiv\varphi(s),
                \spazOr\varphi_*\equiv\varphi(s_*)
                \spazOr\text{e}\spazOr
                \varphi'\equiv\varphi(s').
            \]
            Tal'equazione si può anche derivare, sempre sotto l'ipotesi della propagazione del caos, dalla gerarchia tipo BBGKY (v. se aggiungere il riferimento \daRivedere). In aggiunta si può convertire in forma matriciale introducendo la distribuzione vettoriale \(\mathbf f\equiv\bigl(f_i(s,t)\bigr)_{i\in\mathcal I}\) e la matrice \(\mathbf M\equiv\bigl( A(i,j)\bigr)_{i,j\in\mathcal I}\in\mathbb R^{N\times N}\): 
            %
            \begin{equation}
                \label{eqBoltzmannConGrafoVettoriale}
                \begin{aligned}
                    \derS{}t\int_{\mathcal P}\varphi\mathbf f\de s=&
                    \frac1{2N}\int_{\mathcal P^2}
                    \langle\varphi'-\varphi\rangle
                    \mathbf f\odot\mathbf M\mathbf f_*\de s\de s_*\\&
                    +\frac1{2N}\int_{\mathcal P^2}
                    \langle\varphi'_*-\varphi_*\rangle
                    \mathbf M^\top\mathbf f\odot\mathbf f_*\de s\de s_*,
                \end{aligned}
            \end{equation}
            %
            ove \(\odot\) indica il prodotto di Hadamard e \(\mathbf M^\top\) al trasposta di \(\mathbf M\). Si noti che \(\mathbf M\) altro non è che la matrice d'adiacenza di \(\mathcal G\).
            
        \subsection{Interazioni tra città}
        
            Si può ora approfondire il tipo d'interazioni ipotizzate tra città su grafi.

            Innanzitutto, è chiaro che l'interazione d'interesse sia di tipo «azione-reazione» descritta da \refAlgIntAR{}: infatti, se una città interagisce con un'altra, scambiando popolazione, entrambi variano il proprio stato ma non è detto che la seconda interagisca a sua volta colla prima.

            Tuttavia, se una città può interagire con un'altra, allora è sempre possibile l'opposto; dunque il grafo in questione è diretto ma con struttura indiretta, ovvero la sua matrice d'adiacenza è simmetrica; a livello matematico, ciò implica che la matrice d'adiacenza \(\mathbf M\) è simmetrica.

            Gli stati postinterazione \eqref{eqStatiPostInterazioni} prendono come riferimento leggi d'interazione lineari
            %
            \begin{equation}
                \label{eqStatiPostInterazioniLineari}
                \left\{\begin{alignedat}{2}
                    S_t'&=pS_t&&+qS_t^*,\\
                    S_t^{*\prime}&=p_*S_t&&+q_*S_t^*,
                \end{alignedat}\right.
            \end{equation}
            %
            le quali, specializzate, presentano invece la seguente forma:
            %
            \begin{equation}
                \label{eqSchemaInterazioneCittà}
                \left\{\begin{aligned}
                    s'&=s\bigl(1-E(s,s_*)+\gamma\bigr)\\
                    s_*'&=s_*+sI(s,s_*)
                \end{aligned}\right.
            \end{equation}
            %
            ove \(s\) e \(s_*\) sono le città interagente e subente rispettivamente, \(E(s,s_*)\) e \(I(s,s_*)\) sono rispettivamente i tassi di emigrazione e immigrazione, mentre \(\gamma\) rappresenta fluttuazioni stocastiche da definire; rispetto alle leggi d'interazione lineari \eqref{eqStatiPostInterazioniLineari} le \eqref{eqSchemaInterazioneCittà} soddisfanno
            %
            \begin{equation}
                \label{eqLegameLineareInterazioneCittà}
                % \begin{aligned}
                %     p(s,s_*)&\equiv s[1-E(s,s_*)+\gamma]\\
                %     p_*(s,s_*)&\equiv s_*
                % \end{aligned}
                % \begin{aligned}
                %     \quad&\text{e}\quad\\
                %     \quad&\text{e}\quad
                % \end{aligned}
                % \begin{aligned}
                %     q(s,s_*)&\equiv 0,\\
                %     q_*(s,s_*)&\equiv sI(s,s_*),
                % \end{aligned}
                \begin{alignedat}{3}
                    p(s,s_*)&\equiv s[1-E(s,s_*)+\gamma]
                    \quad&&\text{e}\quad
                    p_*(s,s_*)&&\equiv s_*\\
                    q(s,s_*)&\equiv 0,
                    \quad&&\text{e}\quad
                    q_*(s,s_*)&&\equiv sI(s,s_*),
                \end{alignedat}
            \end{equation}
            %
            rispettivamente per la prima e seconda legge. Ovviamente questo scambio deve conservare [in media] la popolazione totale da cui 
            %
            \begin{equation}
                \label{eqLeggeImmigrazione}
                \begin{aligned}
                    s+s_*&=\langle s+s_*\rangle=
                    \langle s'+s_*'\rangle\\&=
                    s-sE(s,s_*)+s_*+sI(s,s_*)
                \end{aligned}
                \;\;\implies\;\;
                E(s,s_*)=I(s,s_*),
            \end{equation}
            %
            ciò ha senso perché l'emigrazione e l'immigrazione sono fenomeni relativi (invertendo \(s\) ed \(s_*\) sarebbe l'opposto). La scelta di \(E(s,s_*)\) dipende da come si vuole modellizzare il fenomeno dell'immigrazione, e in questo manuscritto si è modificata la \cite[(2.2), § 2, p. 223]{Gualandi2019SDC} mediante la \cite[(4.5), § 4, p. 228]{Gualandi2019SDC}: 
            %
            \begin{equation}
                \label{eqLeggeEmigrazione}
                E(s,s_*)\equiv\lambda\frac{(s_*/s)^\alpha}{1+(s_*/s)^\alpha},
            \end{equation}
            %
            che in essenza è una funzione di Hill di ordine \(\alpha\), in cui v'è un tasso di emigrazione maggiore verso città con popolazione relativa, data dal rapporto \(s_*/s\), maggiore; gli unici due parametri presenti, invece, presentano il seguente significato:

            \begin{itemize}[label=\(\diamond\)]
                \item \(\lambda\in(0,1)\) rappresenta l'attrattività dei poli, ossia la frazione che le città piú popolose riescono al massimo ad attrarre in un'interazione;
                \item \(\alpha\in\mathbb R^+\) indica la rapidità d'emigrazione e influenza quanto rapidamente il rapporto \(s_*/s\) raggiunge la massima attrattività \(\lambda\).
            \end{itemize}

            In poche parole la \eqref{eqLeggeEmigrazione} descrive la tendenza degl'individui di aggregarsi per i piú svariati motivi: lavoro, sicurezza, famiglia, eccetera.

            In questo caso si hanno quindi interazioni non simmetriche, poiché dalla \eqref{eqLegameLineareInterazioneCittà} \(p\neq q\) e \(q\neq p\), e non lineari, a causa della \eqref{eqLeggeEmigrazione}.
            
            % Mediante la conservazione di popolazione ho rifatto molto velocemente i conti della formula prima del Teorema 5.1 a p. 16 di [1], confermando che d⟨s⟩/dt=0, come ci si aspetta da questo tipo d'interazione.

            Non manca che caratterizzare il tipo di perturbazione \(\gamma\) per avere uno stato postinterazione fisicamente sensato; difatti, è chiaro che rigorosamente \(\mathcal P\equiv\mathbb N\) ma è piú agevole supporre \(\mathcal P\equiv\mathbb R^+\) per poi approssimare per eccesso o difetto il numero intero effettivo; pertanto, dalla \eqref{eqSchemaInterazioneCittà}, si ha
            %
            \begin{equation}
                \label{eqVincoloPositivitàFluttuazioni}
                s'>0\;\;\implies\;\;\gamma>E(s,s_*)-1
            \end{equation}
            %
            mentre \(s_*'\) è per definizione sempre positivo. La scelta di \(>\) anziché \(\geq\) nella \eqref{eqVincoloPositivitàFluttuazioni} è ben fondata: di fatto si sta supponendo che le fluttuazioni non possono annullare la popolazione di una città; difatti qualora \(\gamma=E(s,s_*)-1\) si avrebbe \(s'=0\) dalla \eqref{eqSchemaInterazioneCittà}, situazione che si vuole evitare\footnotemark{} dato che nella \eqref{eqLeggeEmigrazione} compare il rapporto tra popolazioni delle città interagenti.

            \footnotetext{Ciò non significa che il modello non possa modellare lo spopolamento di una città, poiché la sua taglia può arbitrariamente avvicinarsi a zero [ma mai esserne uguale], raggiungendolo solo \textit{a posteriori} dopo l'approssimazione dai numeri reali a quelli interi.}

            Perdipiú, le fluttuazioni rappresentano a grandi linee quei fenomeni complessivi di nascita e di morte che vengono considerati ma non direttamente modellati; pertanto \(\gamma\) deve soddisfare le seguenti due caratteristiche:

            \begin{enumerate}[label=F\arabic*]
                \item\label{ipFluttuazioniPositivitàNegatività} possono assumere sia valori positivi che negativi, ma non minori del vincolo imposto da \eqref{eqVincoloPositivitàFluttuazioni};
                \item\label{ipFluttuazioniMediaNulla} la media è scelta arbitrariamente posta allo zero, ossia \(\langle\gamma\rangle=0\);
                \item\label{ipFluttuazioniProbabilitàDecrescente} seppure non vi siano limiti superiori per l'entità della fluttuazione, è chiaro che piú grande questa è meno è probabile.
            \end{enumerate}
            
            Con queste si possono allora analizzare alcune distribuzioni continue:

            \begin{itemize}[label=\(\diamond\)]
                \item la distribuzione normale non soddisfà la \ref{ipFluttuazioniPositivitàNegatività} poiché può assumere valori reali arbitrari con probabilità non nulla;
                \item la distribuzione uniforme è adeguata solo per intervalli finiti e diventa degenere quando un suo estremo diverge, per cui non soddisfà né \ref{ipFluttuazioniMediaNulla} né \ref{ipFluttuazioniProbabilitàDecrescente}, mentre \ref{ipFluttuazioniPositivitàNegatività} si;
                \item la distribuzione esponenziale è quella piú promettente perché riflette sia \ref{ipFluttuazioniMediaNulla} (dopo un'opportuna traslazione dei valori campionati) che \ref{ipFluttuazioniProbabilitàDecrescente}, ma sfortunatamente non \ref{ipFluttuazioniPositivitàNegatività} perché il valore estremo \(\gamma=E(s,s_*)-1\) ha probabilità non nulla [anzi massima] d'essere campionato;
                \item l'unica distribuzione che soddisfà tutt'e tre le caratteristiche ricercate è proprio la distribuzione gamma.
            \end{itemize}

            Si consideri allora una distribuzione gamma avente la seguente funzione di densità di probabilità:
            %
            \begin{equation}
                \label{eqDistribuzioneGamma}
                f(x)=\frac1{\theta\Gamma(\alpha)}x^{\alpha-1}
                \exp\left(-\frac x\theta\right),
            \end{equation}
            %
            ove \(\alpha\) e \(\theta\) sono i parametri rispettivamente di forma e di scala, mentre \(\Gamma(\alpha):\mathbb R^+\to\mathbb R^+\) è la funzione gamma:
            %
            \begin{equation}
                \label{eqFunzioneGamma}
                \Gamma(\alpha)\equiv\int_0^{+\infty}y^{\alpha+1}e^{-y}\de y.
            \end{equation}
            %
            Si scelga \(\hat\gamma\sim\DstrGamma(\alpha,\theta)\), che soddisfà per definizione la \ref{ipFluttuazioniProbabilitàDecrescente}, e s'imponga
            %
            \begin{equation}
                \label{eqMediaVarianzaFluttuazioni}
                \langle\hat\gamma\rangle=1-E(s,s_*)=\alpha\theta
                \quad\text{e}\quad
                \langle\hat\gamma^2\rangle=\sigma^2=\alpha\theta^2,
            \end{equation}
            %
            con \(\sigma\in\mathbb R^+\) equivalente alla deviazione \textit{standard} mentre \(\sigma^2\) alla varianza, da cui
            %
            \begin{equation}
                \label{eqParametriDstrGamma}
                \alpha=\frac{(1-E(s,s_*))^2}{\sigma^2}
                \quad\text{e}\quad
                \theta=\frac{\sigma^2}{1-E(s,s_*)}.
            \end{equation}
            %
            Con tale scelta dei parametri è possibile soddisfare la \ref{ipFluttuazioniMediaNulla} semplicemente traslando i valori campionanti della \(\hat\gamma\) di \(-\langle\hat\gamma\rangle\), ossia si considera la distribuzione \(\gamma\sim\hat\gamma-\langle\hat\gamma\rangle\):
            %
            \begin{equation*}
                %\label{}
                \langle\gamma\rangle=
                \langle\hat\gamma-\langle\hat\gamma\rangle\rangle=
                \langle\hat\gamma\rangle-\langle\hat\gamma\rangle=0.
            \end{equation*}
            %
            D'altra parte la \ref{ipFluttuazioniPositivitàNegatività} necessità di salvaguardarsi dai casi degeneri della distribuzione gamma: essa infatti se \(\alpha=1\) diventa un'esponenziale di parametro \(\theta\), mentre se \(\alpha<1\) diverge all'origine; per avere quindi una probabilità nulla di campionare l'origine [e quindi -\(\langle\hat\gamma\rangle\) dopo la traslazione] è necessario porre
            %
            \begin{equation*}
                %\label{}
                \alpha>1
                \;\;\implies\;\;
                \frac{(1-E(s,s_*))^2}{\sigma^2}>1,
            \end{equation*}
            %
            ma nel caso peggiore \(1-E(s,s_*)=1-\lambda\) da cui
            %
            \begin{equation}
                \label{eqVincoloTraParametri}
                \frac{(1-\lambda)^2}{\sigma^2}>1
                \;\;\implies\;\;
                \sigma^2<(1-\lambda)^2
                \;\;\implies\;\;
                \sigma<\vert1-\lambda\vert=1-\lambda,
            \end{equation}
            %
            siccome \(E(s,s_*)\in(0,\lambda)\;\;\forall s,s_*\in\mathcal P\) e \(\lambda\in(0,1)\). La \eqref{eqVincoloTraParametri} implica quindi che non è possibile avere una varianza arbitraria per poter soddisfare la \ref{ipFluttuazioniPositivitàNegatività}, ma che questa è limitata superiormente dall'attrattività dei poli: piú è grande \(\lambda\) piú piccola è la varianza, e viceversa.

        \subsection{Derivazione approssimata}

    \section{Nesso discreto-continuo}\label{secNessoDC}

        È d'interesse esplorare il legame presente tra la \eqref{eqBoltzmannConGrafo} coll'equazione classica di Boltzmann \daRivedere{}.

        \subsection{Ipotesi semplificative}

            A questo scopo si possono fare tre principali ipotesi semplificative da applicare alla \eqref{eqBoltzmannConGrafo}:

            \begin{enumerate}[
                label=IS\arabic*,
                topsep=0.5em,
                parsep=0em,
                itemsep=0.25em,
                leftmargin=2.5em,
                rightmargin=1.5em,
                % \leftmargin + \itemindent = \labelindent + \labelwidth + \labelsep
                %itemindent=!,
                % labelindent=1em,
                %labelwidth=!,
                %labelsep=!,
            ]
                \item\label{ipMatriceUnitaria} Si presuppone che il grafo sia completamente connesso e quindi che la matrice d'adiacenza sia unitaria \(A\equiv I\).
                %
                \item\label{ipAgentiIndistinguibili} Si assume che gli agenti siano indistinguibili:
                %
                \begin{equation}
                    f_i(s,t)=f_j(s,t)=f(s,t)
                    \quad\forall i,j\in\mathcal I,
                \end{equation}
                %
                \item\label{ipInterazioniSimmetriche} S'ipotizza che le interazioni siano simmetriche:% \(\psi(s,s_*)=\psi_*(s_*,s).\)
                %
                \begin{equation}
                    s'=\Psi(s,s_*)=\Psi_*(s_*,s),
                    \;\;\text{ove }s_*=\Psi_*(s,s_*).
                \end{equation}
            \end{enumerate}

        \subsection{Analisi della \texorpdfstring{\ref{ipMatriceUnitaria}}{IS1}}

            Con tal'ipotesi la \eqref{eqBoltzmannConGrafo} diventa
            %
            \begin{equation*}
                % \begin{aligned}
                %     \derS{}t\int_{\mathcal P}\varphi f_i\de s=
                %     \frac1{2N}\left[\vphantom{\int_{\mathcal P^2}}\right.&
                %     \smash{\sum_{j\in\mathcal I}}\int_{\mathcal P^2}
                %     \langle\varphi'-\varphi\rangle f_if^*_j\de s\de s_*\\
                %     +&\smash{\sum_{j\in\mathcal I}}\int_{\mathcal P^2}
                %     \langle\varphi'_*-\varphi_*\rangle f_jf^*_i\de s\de s_*
                %     \left.\vphantom{\int_{\mathcal P^2}}\right],
                % \end{aligned}
                %
                \derS{}t\int_{\mathcal P}\varphi f_i\de s=
                \frac1{2N}\left[\vphantom{\int_{\mathcal P^2}}\right.
                \smash{\sum_{j\in\mathcal I}}\int_{\mathcal P^2}
                \langle\varphi'-\varphi\rangle f_if^*_j\de s\de s_*
                +\smash{\sum_{j\in\mathcal I}}\int_{\mathcal P^2}
                \langle\varphi'_*-\varphi_*\rangle f_jf^*_i\de s\de s_*
                \left.\vphantom{\int_{\mathcal P^2}}\right],
            \end{equation*}
            %
            e valutando la distribuzione marginale della \eqref{eqDistribuzioneTotale} rispetto agl'indici
            %
            \begin{equation}
                \label{eqDistribuzioneMarginaleIndici}
                F(s,t)\equiv\int_{\mathcal I}f(x,s,t)\de x=
                \frac1N\sum_{i\in\mathcal I}f_i(s,t)
                \otimes\int_{\mathcal I}\delta(x-i)\de x=
                \frac1N\sum_{i\in\mathcal I}f_i(s,t),
            \end{equation}
            %
            che corrisponde a una media tra le distribuzione dei singoli agenti, si ricava
            %
            \begin{equation*}
                % \label{}
                % \begin{aligned}
                %     \derS{}t\int_{\mathcal P}\varphi f_i\de s=
                %     \frac1{2N}\left[\vphantom{\int_{\mathcal P^2}}\right.&
                %     \int_{\mathcal P^2}
                %     \langle\varphi'-\varphi\rangle f_iF^*\de s\de s_*\\
                %     +&\int_{\mathcal P^2}
                %     \langle\varphi'_*-\varphi_*\rangle F_jf^*_i\de s\de s_*
                %     \left.\vphantom{\int_{\mathcal P^2}}\right],
                % \end{aligned}
                %
                \derS{}t\int_{\mathcal P}\varphi f_i\de s=
                \frac12\left[\vphantom{\int_{\mathcal P^2}}\right.
                \int_{\mathcal P^2}
                \langle\varphi'-\varphi\rangle f_iF^*\de s\de s_*
                +\int_{\mathcal P^2}
                \langle\varphi'_*-\varphi_*\rangle Ff^*_i\de s\de s_*
                \left.\vphantom{\int_{\mathcal P^2}}\right];
            \end{equation*}
            %
            mediando ora rispetto a tutti gli agenti, si ha
            %
            \begin{equation}
                \label{eqBoltzmannConGrafoUnitario}
                % \begin{aligned}
                %     \derS{}t\int_{\mathcal P}\varphi F\de s&=
                %     \frac1{2N}\left[\vphantom{\int_{\mathcal P^2}}\right.
                %     \int_{\mathcal P^2}
                %     \langle\varphi'-\varphi\rangle FF^*\de s\de s_*
                %     +\int_{\mathcal P^2}
                %     \langle\varphi'_*-\varphi_*\rangle FF^*\de s\de s_*
                %     \left.\vphantom{\int_{\mathcal P^2}}\right]\\&=
                %     \frac1{2N}\int_{\mathcal P^2}
                %     \langle\varphi'-\varphi+\varphi'_*-\varphi_*\rangle FF^*\de s\de s_*
                % \end{aligned}
                \derS{}t\int_{\mathcal P}\varphi F\de s=
                \frac12\int_{\mathcal P^2}
                \langle\varphi'-\varphi+\varphi'_*-\varphi_*\rangle
                FF^*\de s\de s_*,
            \end{equation}
            %
            la quale è formalmente analoga a quella classica di Boltzmann \daRivedere{}. Ciò significa che con tal'ipotesi semplificativa, nonostante gli agenti siano distinti, questi si possono vedere come indistinguibili purché si consideri la distribuzione media \eqref{eqDistribuzioneMarginaleIndici}.

            Tale risultato è anche confermato a livello pratico nell'algoritmo \ref{algMonteCarlo}, illustrato nel paragrafo a venire, ove una matrice d'adiacenza unitaria porta ad avere un algoritmo del tutto analogo a quello classico; pertanto l'unica distribuzione che può calcolare \ref{algMonteCarlo} è proprio quella media \(F\).

        \subsection{Analisi della \texorpdfstring{\ref{ipAgentiIndistinguibili}}{IS2}}

            La previa discussione suggerisce di studiare anche il caso in cui gli agenti siano effettivamente indistinguibili; tuttavia, prima di affrontarlo assieme alla prima ipotesi risulta interessante analizzare tale ipotesi isolatamente. Pertanto la \eqref{eqBoltzmannConGrafo} diventa
            %
            \begin{equation*}
                \begin{aligned}
                    \derS{}t\int_{\mathcal P}\varphi f\de s&=
                    \frac1{2N}\sum_{j\in\mathcal I}A(i,j)
                    \int_{\mathcal P^2}
                    \langle\varphi'-\varphi\rangle
                    ff^*\de s\de s_*\\&
                    +\frac1{2N}\sum_{j\in\mathcal I}A(j,i)
                    \int_{\mathcal P^2}
                    \langle\varphi'_*-\varphi_*\rangle
                    ff^*\de s\de s_*,
                \end{aligned}
            \end{equation*}
            %
            che sommata su tutti gl'indici porta a
            %
            \begin{equation*}
                \derS{}t\int_{\mathcal P}\varphi f\de s=
                \frac1{2N^2}\sum_{i,j\in\mathcal I}A(i,j)
                \int_{\mathcal P^2}
                \langle\varphi'-\varphi+\varphi'_*-\varphi_*\rangle
                ff^*\de s\de s_*,
            \end{equation*}
            %
            e definendo \(L\equiv\sum_{i,j\in\mathcal I}A(i,j)\) si arriva a
            %
            \begin{equation}
                \label{eqBoltzmannConAgentiIndistinguibili}
                \derS{}t\int_{\mathcal P}\varphi f\de s=
                \frac L{N^2}\left[\frac12
                \smash{\sum_{i,j\in\mathcal I}}A(i,j)
                \int_{\mathcal P^2}
                \langle\varphi'-\varphi+\varphi'_*-\varphi_*\rangle
                ff^*\de s\de s_*\right].
            \end{equation}
            %
            In questo contesto il rapporto \(L/N^2\in[0,1]\) rappresenta topologicamente simile è la rete a una completamente connessa\footnotemark{}; d'altra parte l'equazione è analoga a quella classica di Boltzmann \daRivedere{}.
            
            Dunque l'indistinguibilità degli agenti ha una notevole conseguenza sulla \eqref{eqBoltzmannConGrafo}, riassumendo l'effetto complessivo del grafo al solo coefficiente \(L/N^2\) che quindi ne rappresenta gli ultimi bagliori prima di una sua totale scomparsa per la \ref{ipMatriceUnitaria}.

            \footnotetext{Difatti \(L\) è interpretabile come il numero di lati presenti in un grafo diretto e che ha come limite superiore prorio \(N^2\), ossia il numero totale di coppie [e quindi lati] dati \(N\) nodi.}

        \subsection{Analisi della \texorpdfstring{\ref{ipMatriceUnitaria}, \ref{ipAgentiIndistinguibili} e \ref{ipInterazioniSimmetriche}}{IS1, IS2 e IS3}}

            Visto che vale \ref{ipMatriceUnitaria} si può partire dalla \eqref{eqBoltzmannConGrafoUnitario} nella quale la distribuzione media \eqref{eqDistribuzioneMarginaleIndici} diventa per \ref{ipAgentiIndistinguibili}                %
            \begin{equation*}
                    F(s,t)=\frac1N\sum_{i\in\mathcal I}f_i(s,t)
                    \overset{\tref{ipAgentiIndistinguibili}{2^\circ}}=
                    \frac1N\sum_{i\in\mathcal I}f(s,t)=f(s,t),
            \end{equation*}
            %
            ossia la \(F\) coincide con quella di tutti gli agenti\footnotemark, essendo questi, appunto, indistinguibili.
            \footnotetext{Si noti anche che la perdita della dipendenza della distribuzione media dal numero di nodi \(N\) è coerente colla situazione in cui \(N\to\infty\), condizione fondamentale analoga a casi classici come lo studio del gas nel quale \(N\gg1\) ben approssima il limite.}

            In tal modo la \eqref{eqBoltzmannConGrafoUnitario} diventa
            %
            \begin{equation*}
                \derS{}t\int_{\mathcal P}\varphi f\de s=
                \frac12\int_{\mathcal P^2}
                \langle\varphi'-\varphi+\varphi'_*-\varphi_*\rangle
                ff^*\de s\de s_*,
            \end{equation*}
            %
            che unita all \ref{ipInterazioniSimmetriche} porta all'equivalenza (mediante il cambio di variabili \(s_*=s\) e \(s=s_*\))
            %
            \begin{equation*}
                \int_{\mathcal P^2}
                \langle\varphi_*'-\varphi_*\rangle ff_*dsds_*
                =\int_{\mathcal P^2}
                \langle\varphi'-\varphi\rangle ff^*dsds_*,
            \end{equation*}
            %
            e quindi a
            %
            \begin{equation*}
                \derS{}t\int_{\mathcal P}\varphi fds=
                \int_{\mathcal P^2}
                \langle\varphi'-\varphi\rangle ff^*dsds_*,
            \end{equation*}
            %
            che equivale alla formula classica di Boltzmann con interazioni simmetriche \daRivedere{} usata classicamente per modellizzare la distribuzione dell'energia cinetica tra una popolazione di particelle di un gas.
